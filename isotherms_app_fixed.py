import io
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
from scipy.stats import zscore

st.set_page_config(page_title="Isotermas de Adsor√ß√£o - An√°lise Robusta", layout="wide")
st.title("Isotermas de Adsor√ß√£o com Tratamento de Outliers")
st.write("Aplicativo aprimorado com **ajuste ponderado apenas por œÉ(qe)** e **detec√ß√£o de outliers**.")

def langmuir(C, qmax, KL):
    return (qmax * KL * C) / (1.0 + KL * C)

def freundlich(C, KF, n):
    n = np.maximum(n, 1e-8)
    return KF * np.power(C, 1.0/n)

def temkin(C, B, A):
    return B * np.log(np.maximum(A*C, 1e-12))

def sips(C, qmax, Ks, n):
    """Modelo de Sips: qe = qmax * (Ks*C)^n / (1 + (Ks*C)^n)"""
    x = np.power(np.maximum(Ks*C, 1e-12), np.maximum(n, 1e-8))
    return qmax * x / (1.0 + x)

def redlich_peterson(C, KR, a, g):
    g = np.clip(g, 1e-8, 1.0)
    return (KR * C) / (1.0 + a * np.power(C, g))

def hill_langmuir(C, qmax, K, n):
    """Modelo de Hill-Langmuir: pode ter comportamento sigmoidal com pico"""
    n = np.maximum(n, 0.1)
    Cn = np.power(C, n)
    return (qmax * Cn) / (K + Cn)

def competitive_langmuir(C, qmax1, K1, qmax2, K2):
    """Langmuir competitivo: dois s√≠tios com afinidades diferentes"""
    return (qmax1 * K1 * C) / (1 + K1 * C) + (qmax2 * K2 * C) / (1 + K2 * C)

def toth_modified(C, qmax, KT, n, alpha):
    """T√≥th modificado com termo de inibi√ß√£o"""
    alpha = np.clip(alpha, 0.01, 2.0)
    denominator = (1 + (KT * C)**n)**(1/n) + alpha * C
    return (qmax * KT * C) / denominator

def khan_model(C, qmax, K, beta):
    """Modelo de Khan: adsor√ß√£o com inibi√ß√£o em altas concentra√ß√µes"""
    beta = np.maximum(beta, 0.01)
    return (qmax * K * C) / (1 + K * C + beta * C**2)

def dual_site_langmuir(C, qmax1, K1, qmax2, K2, alpha):
    """Langmuir de dois s√≠tios com intera√ß√£o"""
    alpha = np.clip(alpha, -0.5, 0.5)
    site1 = (qmax1 * K1 * C) / (1 + K1 * C)
    site2 = (qmax2 * K2 * C) / (1 + K2 * C)
    interaction = alpha * site1 * site2 / qmax1 if qmax1 > 0 else 0
    return site1 + site2 + interaction

MODEL_SPECS = {
    "Langmuir": {
        "func": langmuir, 
        "p0": lambda C,q: [np.nanmax(q)*1.2 if np.all(np.isfinite(q)) else 1.0, 1.0/max(np.nanmean(C),1e-6)],
        "bounds": ([0,0],[200, np.inf]),  # Increased from 120 to 200 mg/g
        "params": ["qmax (mg/g)","KL (L/mg)"],
        "equation": "qe = (qmax √ó KL √ó Ce) / (1 + KL √ó Ce)",
        "category": "Cl√°ssico"
    },
    "Freundlich": {
        "func": freundlich, 
        "p0": lambda C,q: [max(np.nanmin(q),1e-3), 2.0],
        "bounds": ([0,0.1],[np.inf,np.inf]),  # n >= 0.1 (mais flex√≠vel que n >= 1)
        "params": ["KF ((mg/g)(L/mg)^(1/n))","n (-)"],
        "equation": "qe = KF √ó Ce^(1/n)",
        "category": "Cl√°ssico"
    },
    "Temkin": {
        "func": temkin, 
        "p0": lambda C,q: [(np.nanmax(q)-np.nanmin(q))/max(np.log(np.nanmax(C))-np.log(np.nanmin(C)),1e-6),
                           np.exp(np.nanmin(q)/max((np.nanmax(q)-np.nanmin(q)),1e-6))/max(np.nanmin(C),1e-6)],
        "bounds": ([0,0],[np.inf,np.inf]), 
        "params": ["B (mg/g)","A (L/mg)"],
        "equation": "qe = B √ó ln(A √ó Ce)",
        "category": "Cl√°ssico"
    },
    "Sips": {
        "func": sips, 
        "p0": lambda C,q: [np.nanmax(q)*1.2, 1.0/max(np.nanmean(C),1e-6), 1.0],
        "bounds": ([0,0,0.1],[200, np.inf, 5.0]),  # Increased from 120 to 200 mg/g
        "params": ["qmax (mg/g)","Ks (L/mg)","n (-)"],
        "equation": "qe = qmax √ó (Ks√óCe)^n / (1 + (Ks√óCe)^n)",
        "category": "Cl√°ssico"
    },
    "Redlich-Peterson": {
        "func": redlich_peterson, 
        "p0": lambda C,q: [max(np.nanmean(q)/max(np.nanmean(C),1e-6),1e-3),
                           1.0/max(np.nanmax(C),1e-6), 0.8],
        "bounds": ([0,0,0.1],[np.inf,np.inf,1.0]), 
        "params": ["KR (L/g)","a (L/mg)^g","g (-)"],
        "equation": "qe = (KR √ó Ce) / (1 + a √ó Ce^g)",
        "category": "Cl√°ssico"
    },
    # MODELOS AVAN√áADOS PARA COMPORTAMENTO N√ÉO-MONOT√îNICO
    "Hill-Langmuir": {
        "func": hill_langmuir,
        "p0": lambda C,q: [np.nanmax(q)*0.95, np.nanmean(C), 1.5],
        "bounds": ([0,0,0.1],[110, 300, 5.0]),  # qmax ‚â§ 110 mg/g
        "params": ["qmax (mg/g)","K (mg/L)^n","n (-)"],
        "equation": "qe = qmax √ó Ce^n / (K + Ce^n)",
        "category": "N√£o-monot√¥nico"
    },
    "Langmuir Competitivo": {
        "func": competitive_langmuir,
        "p0": lambda C,q: [np.nanmax(q)*0.5, 1.0/max(np.nanmean(C),1e-6), 
                          np.nanmax(q)*0.5, 0.1/max(np.nanmean(C),1e-6)],
        "bounds": ([0,0,0,0],[55, 1.0, 55, 1.0]),  # 55+55 = 110 mg/g total
        "params": ["qmax1 (mg/g)","K1 (L/mg)","qmax2 (mg/g)","K2 (L/mg)"],
        "equation": "qe = (qmax1√óK1√óCe)/(1+K1√óCe) + (qmax2√óK2√óCe)/(1+K2√óCe)",
        "category": "N√£o-monot√¥nico"
    },
    "T√≥th Modificado": {
        "func": toth_modified,
        "p0": lambda C,q: [np.nanmax(q)*0.95, 1.0/max(np.nanmean(C),1e-6), 1.0, 0.01],
        "bounds": ([0,0,0.1,0.001],[110, 1.0, 3.0, 0.1]),  # qmax ‚â§ 110 mg/g
        "params": ["qmax (mg/g)","KT (L/mg)","n (-)","Œ± (inibi√ß√£o)"],
        "equation": "qe = qmax√óKT√óCe / [(1+(KT√óCe)^n)^(1/n) + Œ±√óCe]",
        "category": "N√£o-monot√¥nico"
    },
    "Khan (Inibi√ß√£o)": {
        "func": khan_model,
        "p0": lambda C,q: [np.nanmax(q)*0.95, 1.0/max(np.nanmean(C),1e-6), 1e-6],
        "bounds": ([0,0,1e-8],[110, 1.0, 1e-3]),  # qmax ‚â§ 110 mg/g
        "params": ["qmax (mg/g)","K (L/mg)","Œ≤ (inibi√ß√£o)"],
        "equation": "qe = (qmax√óK√óCe) / (1 + K√óCe + Œ≤√óCe¬≤)",
        "category": "N√£o-monot√¥nico"
    },
    "Langmuir Duplo": {
        "func": dual_site_langmuir,
        "p0": lambda C,q: [np.nanmax(q)*0.5, 1.0/max(np.nanmean(C),1e-6),
                          np.nanmax(q)*0.5, 0.5/max(np.nanmean(C),1e-6), 0.1],
        "bounds": ([0,0,0,0,-0.5],[55, 1.0, 55, 1.0, 0.5]),  # 55+55 = 110 mg/g total
        "params": ["qmax1 (mg/g)","K1 (L/mg)","qmax2 (mg/g)","K2 (L/mg)","Œ± (intera√ß√£o)"],
        "equation": "qe = Site1 + Site2 + Œ±√ó(Site1√óSite2/qmax1)",
        "category": "N√£o-monot√¥nico"
    }
}

def detect_columns(df):
    cols = {c.lower(): c for c in df.columns}
    def find(cands):
        for cand in cands:
            for key, orig in cols.items():
                if cand in key.replace(" ",""):
                    return orig
        return None
    m = {}
    m["Ce"] = find(["ce(mg/l)","ce","c_e","ce_mg/l","ce(mg l)","ce(mg¬∑l^-1)","ce(mg.l-1)"])
    m["qe"] = find(["qe(mg/g)","qe","q_e","qe_mg/g","qe(mg g)","qe(mg¬∑g^-1)","qe(mg.g-1)"])
    m["sigma_Ce"] = find(["¬±ce","sdce","sigmace","s_ce","stdce","sd_ce","sigma_ce"])
    m["sigma_qe"] = find(["¬±qe","sdqe","sigmaqe","s_qe","stdqe","sd_qe","sigma_qe"])
    return m

def weighted_r2(y, yhat, w):
    ybar = np.sum(w*y)/np.sum(w)
    ss_res = np.sum(w*(y-yhat)**2)
    ss_tot = np.sum(w*(y-ybar)**2)
    return (1.0 - ss_res/ss_tot) if ss_tot>0 else np.nan, ss_res

def aic_bic(ss_res_w, n, k):
    aic = n*np.log(ss_res_w/max(n,1)) + 2*k
    bic = n*np.log(ss_res_w/max(n,1)) + k*np.log(max(n,1))
    return aic, bic

def adjust_bounds_to_data(model_name, bounds, Ce_data, qe_data, bounds_mode="Livres (sem limita√ß√£o)"):
    """Ajusta bounds dinamicamente baseado nos dados experimentais e modo selecionado"""
    if bounds_mode == "Livres (sem limita√ß√£o)":
        # Bounds totalmente livres - apenas limites t√©cnicos m√≠nimos necess√°rios
        lower, upper = bounds
        return bounds  # Retorna bounds originais sem modifica√ß√£o
    
    qe_max = np.nanmax(qe_data) if len(qe_data) > 0 else 110
    Ce_max = np.nanmax(Ce_data) if len(Ce_data) > 0 else 200
    
    lower, upper = bounds
    upper = list(upper)
    
    if bounds_mode == "Conservadores (baseados nos dados)":
        # Bounds baseados nos dados experimentais - MAIS PERMISSIVOS
        if model_name in ["Langmuir", "Sips", "Hill-Langmuir", "T√≥th Modificado", "Khan (Inibi√ß√£o)"]:
            # qmax limitado a 200% dos dados experimentais (era 150%)
            qmax_limit = qe_max * 2.0  # INCREASED FROM 1.5 to 2.0
            # Ensure minimum bound is not below experimental maximum + 10%
            qmax_minimum = qe_max * 1.1
            qmax_limit = max(qmax_limit, qmax_minimum)
            
            if len(upper) > 0 and upper[0] != np.inf:
                upper[0] = max(min(upper[0], qmax_limit), qmax_minimum)  # FIXED: ensure not below experimental max
            elif len(upper) > 0:
                upper[0] = qmax_limit
                
        elif model_name in ["Langmuir Competitivo", "Langmuir Duplo"]:
            # Cada s√≠tio limitado a ~100% dos dados experimentais (era 75%)
            site_limit = qe_max * 1.0  # INCREASED FROM 0.75 to 1.0
            site_minimum = qe_max * 0.6  # Minimum 60% of experimental max per site
            site_limit = max(site_limit, site_minimum)
            
            if len(upper) > 0:
                upper[0] = max(min(upper[0], site_limit) if upper[0] != np.inf else site_limit, site_minimum)
            if len(upper) >= 3:
                upper[2] = max(min(upper[2], site_limit) if upper[2] != np.inf else site_limit, site_minimum)
                
    elif bounds_mode == "Ultra-restritivos (‚â§115 mg/g)":
        # Bounds ultra-restritivos originais - KEEP SAME BUT ADD MINIMUM CHECK
        if model_name in ["Langmuir", "Sips"]:
            qmax_limit = min(qe_max * 1.2, 120)  # INCREASED FROM 1.05 to 1.2
            qmax_minimum = qe_max * 1.05  # Minimum 5% above experimental
            upper[0] = max(qmax_limit, qmax_minimum)
        elif model_name in ["Hill-Langmuir", "T√≥th Modificado", "Khan (Inibi√ß√£o)"]:
            qmax_limit = min(qe_max * 1.15, 115)  # INCREASED FROM 1.02 to 1.15
            qmax_minimum = qe_max * 1.05
            upper[0] = max(qmax_limit, qmax_minimum)
        elif model_name in ["Langmuir Competitivo", "Langmuir Duplo"]:
            site_limit = min(qe_max * 0.6, 57)  # INCREASED FROM 0.52 to 0.6
            site_minimum = qe_max * 0.45
            site_limit = max(site_limit, site_minimum)
            upper[0] = site_limit
            if len(upper) >= 3:
                upper[2] = site_limit
    
    return (lower, tuple(upper))

def validate_parameters(model_name, params, qe_max, is_nonmonotonic=False, bounds_mode="Livres (sem limita√ß√£o)"):
    """Valida se os par√¢metros est√£o fisicamente realistas"""
    warnings = []
    
    if bounds_mode == "Livres (sem limita√ß√£o)":
        # Valida√ß√£o muito branda para bounds livres
        if model_name in ["Langmuir", "Sips", "Hill-Langmuir"]:
            qmax = params[0]
            if qmax > qe_max * 3:  # Apenas avisar se muito exagerado
                warnings.append(f"‚ÑπÔ∏è qmax ({qmax:.1f}) √© 3√ó maior que qe_experimental ({qe_max:.1f})")
        elif model_name in ["Langmuir Competitivo", "Langmuir Duplo"]:
            qmax_total = params[0] + params[2]
            if qmax_total > qe_max * 3:
                warnings.append(f"‚ÑπÔ∏è qmax_total ({qmax_total:.1f}) √© 3√ó maior que qe_experimental")
        elif model_name in ["T√≥th Modificado", "Khan (Inibi√ß√£o)"]:
            qmax = params[0]
            if qmax > qe_max * 3:
                warnings.append(f"‚ÑπÔ∏è qmax ({qmax:.1f}) √© muito alto - verifique se √© fisicamente realista")
        
        # Avisos sobre adequa√ß√£o do modelo (independente dos bounds)
        if is_nonmonotonic:
            if model_name in ["Freundlich", "Temkin"]:
                warnings.append(f"‚ö†Ô∏è {model_name} pode ser inadequado para dados n√£o-monot√¥nicos")
        
        return warnings
    
    # Valida√ß√µes mais rigorosas para bounds conservadores/restritivos
    if model_name in ["Langmuir", "Sips", "Hill-Langmuir"]:
        qmax = params[0]
        if bounds_mode == "Ultra-restritivos (‚â§115 mg/g)":
            if qmax > qe_max * 1.1:
                warnings.append(f"üö® qmax ({qmax:.1f}) > qe_experimental √ó 1.1 ({qe_max*1.1:.1f})")
            if qmax > 120 and model_name in ["Langmuir", "Sips"]:
                warnings.append(f"üö® qmax ({qmax:.1f}) > 120 mg/g (limite f√≠sico)")
            if qmax > 115 and model_name == "Hill-Langmuir":
                warnings.append(f"üö® qmax ({qmax:.1f}) > 115 mg/g (limite para n√£o-monot√¥nico)")
        else:  # Conservadores
            if qmax > qe_max * 2:
                warnings.append(f"‚ö†Ô∏è qmax ({qmax:.1f}) > 2√ó qe_experimental ({qe_max*2:.1f})")
    
    elif model_name in ["Langmuir Competitivo", "Langmuir Duplo"]:
        qmax_total = params[0] + params[2]
        threshold = qe_max * 1.1 if bounds_mode == "Ultra-restritivos (‚â§115 mg/g)" else qe_max * 2
        if qmax_total > threshold:
            warnings.append(f"‚ö†Ô∏è qmax_total ({qmax_total:.1f}) > {threshold:.1f} mg/g")
    
    elif model_name in ["T√≥th Modificado", "Khan (Inibi√ß√£o)"]:
        qmax = params[0]
        if bounds_mode == "Ultra-restritivos (‚â§115 mg/g)":
            if qmax > qe_max * 1.05:
                warnings.append(f"üö® qmax ({qmax:.1f}) > qe_experimental √ó 1.05 ({qe_max*1.05:.1f})")
        else:  # Conservadores
            if qmax > qe_max * 2:
                warnings.append(f"‚ö†Ô∏è qmax ({qmax:.1f}) > 2√ó qe_experimental ({qe_max*2:.1f})")
    
    # Avisos espec√≠ficos para modelos inadequados em dados n√£o-monot√¥nicos
    if is_nonmonotonic:
        if model_name in ["Freundlich", "Temkin"]:
            warnings.append(f"‚ö†Ô∏è Modelo {model_name} √© INADEQUADO para dados n√£o-monot√¥nicos")
        elif model_name in ["Langmuir", "Sips", "Redlich-Peterson"]:
            warnings.append(f"‚ö†Ô∏è Modelo {model_name} assume comportamento monot√¥nico")
    
    return warnings

def detect_outliers(Ce, qe, method="zscore", threshold=2.0):
    """Detecta outliers usando diferentes m√©todos"""
    if method == "zscore":
        z_scores = np.abs(zscore(qe))
        outliers = z_scores > threshold
    elif method == "iqr":
        Q1 = np.percentile(qe, 25)
        Q3 = np.percentile(qe, 75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers = (qe < lower_bound) | (qe > upper_bound)
    elif method == "monotonic":
        # Detecta pontos que quebram a monotonicidade esperada
        outliers = np.zeros(len(qe), dtype=bool)
        for i in range(len(qe)-1):
            if qe[i+1] < qe[i] * 0.8:  # Redu√ß√£o > 20%
                outliers[i+1] = True
    return outliers

st.sidebar.header("üìä Entrada de dados")
uploaded = st.sidebar.file_uploader("Carregue um arquivo (.xlsx ou .csv)", type=["xlsx","csv"])

def detect_nonmonotonic_behavior(Ce, qe):
    """Detecta se os dados apresentam comportamento n√£o-monot√¥nico"""
    if len(Ce) < 3:
        return False, "Poucos pontos para an√°lise"
    
    # Ordenar por Ce para an√°lise
    sorted_indices = np.argsort(Ce)
    Ce_sorted = Ce[sorted_indices]
    qe_sorted = qe[sorted_indices]
    
    # Encontrar o ponto de qe m√°ximo
    max_idx = np.argmax(qe_sorted)
    qe_max = qe_sorted[max_idx]
    Ce_at_max = Ce_sorted[max_idx]
    
    # Verificar se h√° pontos ap√≥s o m√°ximo com qe significativamente menor
    points_after_max = qe_sorted[max_idx+1:] if max_idx < len(qe_sorted)-1 else []
    
    if len(points_after_max) == 0:
        return False, f"Sem pontos ap√≥s qe_max ({qe_max:.1f} mg/g)"
    
    # Crit√©rio: redu√ß√£o > 5% do qe_max em pontos subsequentes
    min_after_max = np.min(points_after_max)
    reduction_pct = (qe_max - min_after_max) / qe_max * 100
    
    is_nonmonotonic = reduction_pct > 5.0
    
    if is_nonmonotonic:
        message = f"‚úÖ Comportamento n√£o-monot√¥nico detectado!\n"
        message += f"   qe_max: {qe_max:.1f} mg/g (Ce = {Ce_at_max:.1f} mg/L)\n"
        message += f"   Redu√ß√£o: {reduction_pct:.1f}% ap√≥s o pico\n"
        message += f"   ‚Üí Recomendados: Modelos avan√ßados (Hill, T√≥th, Khan)"
    else:
        message = f"‚ùå Comportamento aparentemente monot√¥nico (redu√ß√£o: {reduction_pct:.1f}%)\n"
        message += f"   ‚Üí Adequados: Modelos cl√°ssicos (Langmuir, Freundlich)"
    
    return is_nonmonotonic, message

st.sidebar.subheader("üéØ Sele√ß√£o de Modelos")

# Organizar modelos por categoria
classic_models = [name for name, spec in MODEL_SPECS.items() if spec.get("category") == "Cl√°ssico"]
advanced_models = [name for name, spec in MODEL_SPECS.items() if spec.get("category") == "N√£o-monot√¥nico"]

st.sidebar.markdown("**üìö Modelos Cl√°ssicos (Monot√¥nicos)**")
chosen_models = []
for m in classic_models:
    if st.sidebar.checkbox(m, value=True, key=f"classic_{m}"):
        chosen_models.append(m)

st.sidebar.markdown("**üî¨ Modelos Avan√ßados (N√£o-monot√¥nicos)**")
st.sidebar.markdown("*Adequados para sistemas com redu√ß√£o em altas concentra√ß√µes*")
for m in advanced_models:
    if st.sidebar.checkbox(m, value=False, key=f"advanced_{m}"):
        chosen_models.append(m)

st.sidebar.subheader("üîß Tratamento de Dados")

# Op√ß√£o de bounds
bounds_mode = st.sidebar.selectbox(
    "Tipo de bounds para par√¢metros", 
    ["Livres (sem limita√ß√£o)", "Conservadores (baseados nos dados)", "Ultra-restritivos (‚â§115 mg/g)"],
    index=0
)

if bounds_mode == "Livres (sem limita√ß√£o)":
    st.sidebar.info("üÜì **Bounds livres**: Permite qmax ilimitado - adequado para explorar diferentes sistemas")
elif bounds_mode == "Conservadores (baseados nos dados)":
    st.sidebar.info("üéØ **Bounds conservadores**: qmax limitado a ~200% dos dados experimentais (ATUALIZADO)")
else:
    st.sidebar.warning("üîí **Bounds ultra-restritivos**: qmax ‚â§ 115 mg/g - apenas para sistemas espec√≠ficos")

# Sugerir m√©todo baseado nos modelos selecionados
has_nonmonotonic = any(MODEL_SPECS[m].get("category") == "N√£o-monot√¥nico" for m in chosen_models)
if has_nonmonotonic:
    st.sidebar.info("üí° **Modelos n√£o-monot√¥nicos selecionados!** Considere usar 'Z-Score' ou 'IQR' ao inv√©s de 'Monotonicidade'.")

outlier_method = st.sidebar.selectbox(
    "M√©todo de detec√ß√£o de outliers", 
    ["Nenhum", "Z-Score", "IQR", "Monotonicidade"], 
    index=0 if has_nonmonotonic else 3
)

# Definir outlier_action em todos os casos
outlier_action = "Nenhum"
z_threshold = 2.0

if outlier_method != "Nenhum":
    outlier_action = st.sidebar.selectbox(
        "A√ß√£o para outliers", 
        ["Marcar apenas", "Reduzir peso (10%)", "Excluir do ajuste"], 
        index=1
    )
    
    if outlier_method == "Z-Score":
        z_threshold = st.sidebar.slider("Limiar Z-Score", 1.0, 3.0, 2.0, 0.1)

st.sidebar.subheader("üìà Configura√ß√µes de Plot")
x_grid_factor = st.sidebar.slider("Extens√£o do grid de Ce", 0.5, 2.0, 1.2, 0.05)
show_comparison = st.sidebar.checkbox("Mostrar compara√ß√£o com/sem outliers", True)

if uploaded is not None:
    df = pd.read_excel(uploaded) if uploaded.name.endswith(".xlsx") else pd.read_csv(uploaded)
    st.subheader("üìã Pr√©-visualiza√ß√£o dos dados")
    st.dataframe(df.head())

    mapping = detect_columns(df)
    st.markdown("### üéØ Mapeamento de colunas")
    col1, col2 = st.columns(2)
    with col1:
        Ce_col = st.selectbox("Coluna de Ce (mg/L)", df.columns, 
                             index=(df.columns.get_loc(mapping["Ce"]) if mapping["Ce"] in df.columns else 0))
        qe_col = st.selectbox("Coluna de qe (mg/g)", df.columns, 
                             index=(df.columns.get_loc(mapping["qe"]) if mapping["qe"] in df.columns else (1 if len(df.columns)>1 else 0)))
    with col2:
        sigma_Ce_col = st.selectbox("Coluna de œÉCe (mg/L) - Apenas para visualiza√ß√£o", [None]+list(df.columns),
                                   index=(( [None]+list(df.columns) ).index(mapping["sigma_Ce"]) if mapping["sigma_Ce"] in ([None]+list(df.columns)) else 0))
        sigma_qe_col = st.selectbox("Coluna de œÉqe (mg/g) - Para pondera√ß√£o", [None]+list(df.columns),
                                   index=(( [None]+list(df.columns) ).index(mapping["sigma_qe"]) if mapping["sigma_qe"] in ([None]+list(df.columns)) else 0))

    Ce = df[Ce_col].astype(float).to_numpy()
    qe = df[qe_col].astype(float).to_numpy()
    
    # üîç DETEC√á√ÉO AUTOM√ÅTICA DE COMPORTAMENTO N√ÉO-MONOT√îNICO
    is_nonmonotonic, behavior_msg = detect_nonmonotonic_behavior(Ce, qe)
    
    if is_nonmonotonic:
        st.success("üéØ **COMPORTAMENTO N√ÉO-MONOT√îNICO DETECTADO!**")
        st.info(behavior_msg)
        st.warning("‚ö†Ô∏è **RECOMENDA√á√ÉO**: Desmarque modelos cl√°ssicos inadequados (Freundlich, Temkin) e foque nos **modelos avan√ßados**")
    else:
        st.info("üìà **Comportamento aparentemente monot√¥nico detectado**")
        st.info(behavior_msg)
    
    if sigma_qe_col is None:
        st.warning("‚ö†Ô∏è œÉ(qe) n√£o informado ‚Äì ajuste **n√£o ponderado**. Recomenda-se œÉ(qe).")
        sigma_qe = np.ones_like(qe)
    else:
        sigma_qe = df[sigma_qe_col].astype(float).to_numpy()
        sigma_qe = np.where(sigma_qe<=0, np.nanmedian(sigma_qe[sigma_qe>0]) if np.any(sigma_qe>0) else 1.0, sigma_qe)
    
    sigma_Ce = np.zeros_like(Ce) if sigma_Ce_col is None else df[sigma_Ce_col].astype(float).to_numpy()
    
    # Detectar outliers
    outliers = np.zeros(len(qe), dtype=bool)  # Sempre inicializar como False
    if outlier_method == "Z-Score":
        outliers = detect_outliers(Ce, qe, "zscore", z_threshold)
    elif outlier_method == "IQR":
        outliers = detect_outliers(Ce, qe, "iqr")
    elif outlier_method == "Monotonicidade":
        outliers = detect_outliers(Ce, qe, "monotonic")
    
    if outlier_method != "Nenhum" and np.any(outliers):
        st.warning(f"üö® **{np.sum(outliers)} outlier(s) detectado(s)** nos √≠ndices: {np.where(outliers)[0]}")
        outlier_df = pd.DataFrame({
            '√çndice': np.where(outliers)[0],
            'Ce (mg/L)': Ce[outliers],
            'qe (mg/g)': qe[outliers],
            'œÉqe (mg/g)': sigma_qe[outliers] if sigma_qe_col else "N/A"
        })
        st.dataframe(outlier_df)
    
    # Preparar dados para ajuste
    if outlier_method != "Nenhum" and outlier_action == "Excluir do ajuste" and np.any(outliers):
        mask = ~outliers
        Ce_fit, qe_fit, sigma_qe_fit = Ce[mask], qe[mask], sigma_qe[mask]
        st.info(f"‚úÇÔ∏è Ajuste realizado com {len(Ce_fit)} pontos (exclu√≠dos {np.sum(outliers)} outliers)")
    else:
        Ce_fit, qe_fit, sigma_qe_fit = Ce.copy(), qe.copy(), sigma_qe.copy()
        if outlier_method != "Nenhum" and outlier_action == "Reduzir peso (10%)" and np.any(outliers):
            sigma_qe_fit[outliers] *= np.sqrt(10)  # Reduz peso em 10x
            st.info("‚öñÔ∏è Peso dos outliers reduzido para 10%")
    
    w_fit = 1.0/(sigma_qe_fit**2)
    
    # Ajustar modelos
    results = {}
    results_full = {}  # Para compara√ß√£o com todos os pontos
    
    if bounds_mode != "Livres (sem limita√ß√£o)":
        st.markdown("### üîß **Aplicando Bounds Baseados nos Dados**")
        bounds_info = []
    
    for name in chosen_models:
        spec = MODEL_SPECS[name]
        func = spec["func"]
        
        # Ajuste com dados filtrados
        try:
            p0 = spec["p0"](Ce_fit, qe_fit)
            bounds = spec["bounds"]
            
            # Ajustar bounds dinamicamente baseado nos dados e modo selecionado
            original_bounds = bounds
            bounds = adjust_bounds_to_data(name, bounds, Ce_fit, qe_fit, bounds_mode)
            
            # Capturar informa√ß√µes sobre limites aplicados apenas se n√£o for livre
            if bounds_mode != "Livres (sem limita√ß√£o)":
                if name in ["Langmuir", "Sips"]:
                    qmax_limit = bounds[1][0] if bounds[1][0] != np.inf else "‚àû"
                    bounds_info.append(f"üîß **{name}**: qmax ‚â§ {qmax_limit:.1f}" if isinstance(qmax_limit, (int, float)) else f"üîß **{name}**: qmax ‚â§ {qmax_limit}")
                elif name in ["Hill-Langmuir", "T√≥th Modificado", "Khan (Inibi√ß√£o)"]:
                    qmax_limit = bounds[1][0] if bounds[1][0] != np.inf else "‚àû"
                    bounds_info.append(f"üîß **{name}**: qmax ‚â§ {qmax_limit:.1f}" if isinstance(qmax_limit, (int, float)) else f"üîß **{name}**: qmax ‚â§ {qmax_limit}")
                elif name in ["Langmuir Competitivo", "Langmuir Duplo"]:
                    site_limit = bounds[1][0] if bounds[1][0] != np.inf else "‚àû"
                    bounds_info.append(f"üîß **{name}**: cada s√≠tio ‚â§ {site_limit:.1f}" if isinstance(site_limit, (int, float)) else f"üîß **{name}**: cada s√≠tio ‚â§ {site_limit}")
            
            popt, pcov = curve_fit(func, Ce_fit, qe_fit, sigma=sigma_qe_fit, 
                                 absolute_sigma=True, p0=p0, bounds=bounds, maxfev=500000)
            perr = np.sqrt(np.diag(pcov))
            qhat = func(Ce_fit, *popt)
            R2w, ss_res_w = weighted_r2(qe_fit, qhat, w_fit)
            k, n = len(popt), len(qe_fit)
            aic, bic = aic_bic(ss_res_w, n, k)
            results[name] = {"popt": popt, "perr": perr, "R2w": R2w, "aic": aic, "bic": bic, "func": func}
        except Exception as e:
            if bounds_mode != "Livres (sem limita√ß√£o)":
                bounds_info.append(f"‚ùå **{name}**: Falha no ajuste - {str(e)[:50]}...")
            results[name] = {"error": str(e)}
        
        # Ajuste com todos os dados (para compara√ß√£o)
        if show_comparison and outlier_method != "Nenhum" and np.any(outliers):
            try:
                w_full = 1.0/(sigma_qe**2)
                p0_full = spec["p0"](Ce, qe)
                bounds_full = adjust_bounds_to_data(name, spec["bounds"], Ce, qe, bounds_mode)
                popt_full, pcov_full = curve_fit(func, Ce, qe, sigma=sigma_qe, 
                                               absolute_sigma=True, p0=p0_full, bounds=bounds_full, maxfev=500000)
                qhat_full = func(Ce, *popt_full)
                R2w_full, _ = weighted_r2(qe, qhat_full, w_full)
                results_full[name] = {"popt": popt_full, "R2w": R2w_full, "func": func}
            except:
                results_full[name] = {"error": "Falha"}
    
    # Mostrar bounds aplicados apenas se n√£o for livre
    if bounds_mode != "Livres (sem limita√ß√£o)" and bounds_info:
        st.info(f"**Limites aplicados automaticamente ({bounds_mode}):**")
        for info in bounds_info:
            st.write(info)

    # Exibir resultados
    st.markdown("### üìä Resultados dos Ajustes")
    
    # Separar por categoria e validar par√¢metros
    classic_results = []
    advanced_results = []
    qe_max_exp = np.nanmax(qe_fit)
    
    for name in chosen_models:
        res = results.get(name, {})
        category = MODEL_SPECS[name].get("category", "Cl√°ssico")
        
        if "error" in res:
            row = {"Modelo": name, "Status": f"‚ùå {res['error'][:50]}..."}
        else:
            spec = MODEL_SPECS[name]
            row = {"Modelo": name, "R¬≤ ponderado": f"{res['R2w']:.4f}", 
                   "AIC": f"{res['aic']:.2f}", "BIC": f"{res['bic']:.2f}"}
            
            # Validar par√¢metros
            param_warnings = validate_parameters(name, res["popt"], qe_max_exp, is_nonmonotonic, bounds_mode)
            if param_warnings:
                row["‚ö†Ô∏è Avisos"] = " | ".join(param_warnings)
            
            # Adicionar compara√ß√£o se dispon√≠vel
            if name in results_full and "error" not in results_full[name]:
                row["R¬≤ (todos pontos)"] = f"{results_full[name]['R2w']:.4f}"
                delta_r2 = res['R2w'] - results_full[name]['R2w']
                row["ŒîR¬≤"] = f"{delta_r2:+.4f}"
            
            for pname, val, err in zip(spec["params"], res["popt"], res["perr"]):
                row[pname] = f"{val:.4g} ¬± {err:.2g}"
        
        if category == "Cl√°ssico":
            classic_results.append(row)
        else:
            advanced_results.append(row)
    
    # Exibir tabelas separadas
    if classic_results:
        st.markdown("#### üìö **Modelos Cl√°ssicos**")
        classic_df = pd.DataFrame(classic_results).set_index("Modelo")
        st.dataframe(classic_df, use_container_width=True)
    
    if advanced_results:
        st.markdown("#### üî¨ **Modelos Avan√ßados (N√£o-monot√¥nicos)**")
        advanced_df = pd.DataFrame(advanced_results).set_index("Modelo")
        st.dataframe(advanced_df, use_container_width=True)
        
        # Destacar o melhor modelo n√£o-monot√¥nico
        if len(advanced_results) > 0:
            best_advanced = max([r for r in advanced_results if "R¬≤ ponderado" in r], 
                              key=lambda x: float(x["R¬≤ ponderado"]), default=None)
            if best_advanced:
                st.success(f"üèÜ **Melhor modelo para comportamento n√£o-monot√¥nico**: {best_advanced['Modelo']} (R¬≤ = {best_advanced['R¬≤ ponderado']})")
        
        # Alertas sobre par√¢metros problem√°ticos
        problematic_models = [r for r in advanced_results if "‚ö†Ô∏è Avisos" in r]
        if problematic_models:
            st.markdown("#### üö® **Alertas de Valida√ß√£o de Par√¢metros**")
            for model in problematic_models:
                st.warning(f"**{model['Modelo']}**: {model['‚ö†Ô∏è Avisos']}")
    
    # Tabela combinada para download
    all_results = classic_results + advanced_results
    result_df = pd.DataFrame(all_results).set_index("Modelo")
    st.dataframe(result_df)
    
    # Download dos par√¢metros
    if 'result_df' in locals():
        csv_data = result_df.to_csv().encode("utf-8")
        st.download_button("üì• Baixar par√¢metros (.csv)", data=csv_data, 
                          file_name="isotermas_parametros.csv", mime="text/csv")

    # Gerar curvas para plotagem
    Ce_min_pos = np.nanmin(Ce[Ce>0]) if np.any(Ce>0) else np.nanmin(Ce)
    Ce_grid = np.linspace(max(1e-9, 0.8*Ce_min_pos), np.nanmax(Ce)*float(x_grid_factor), 200)
    
    pred_dict = {"Ce_grid": Ce_grid}
    for name in chosen_models:
        res = results.get(name, {})
        if "error" in res: continue
        pred_dict[f"{name}_filtrado"] = res["func"](Ce_grid, *res["popt"])
        
        if (outlier_method != "Nenhum" and name in results_full and 
            "error" not in results_full[name]):
            pred_dict[f"{name}_todos"] = results_full[name]["func"](Ce_grid, *results_full[name]["popt"])
    
    pred_df = pd.DataFrame(pred_dict)

    # Gr√°fico principal
    st.markdown("### üìà Curvas ajustadas")
    
    fig, ax = plt.subplots(figsize=(10,7), dpi=120)
    
    # Plotar dados experimentais
    colors = ['blue', 'red', 'green', 'purple', 'brown']
    
    # Pontos normais
    normal_mask = ~outliers if outlier_method != "Nenhum" and np.any(outliers) else np.ones(len(Ce), dtype=bool)
    if np.any(normal_mask):
        ax.errorbar(Ce[normal_mask], qe[normal_mask], 
                   xerr=sigma_Ce[normal_mask] if sigma_Ce_col else None,
                   yerr=sigma_qe[normal_mask], 
                   fmt='o', capsize=4, color='blue', alpha=0.8,
                   label='Dados experimentais')
    
    # Outliers
    if outlier_method != "Nenhum" and np.any(outliers):
        ax.errorbar(Ce[outliers], qe[outliers], 
                   xerr=sigma_Ce[outliers] if sigma_Ce_col else None,
                   yerr=sigma_qe[outliers], 
                   fmt='s', capsize=4, color='red', alpha=0.8,
                   label=f'Outliers ({outlier_method})')
    
    # Plotar curvas ajustadas
    for i, name in enumerate(chosen_models):
        res = results.get(name, {})
        if "error" in res: continue
        
        color = colors[i % len(colors)]
        
        # Curva com dados filtrados
        ax.plot(Ce_grid, res["func"](Ce_grid, *res["popt"]), 
               color=color, linewidth=2.5, linestyle='-',
               label=f'{name} (R¬≤={res["R2w"]:.3f})')
        
        # Curva com todos os dados (pontilhada)
        if (show_comparison and outlier_method != "Nenhum" and 
            name in results_full and "error" not in results_full[name]):
            ax.plot(Ce_grid, results_full[name]["func"](Ce_grid, *results_full[name]["popt"]), 
                   color=color, linewidth=1.5, linestyle='--', alpha=0.7,
                   label=f'{name} - todos pontos (R¬≤={results_full[name]["R2w"]:.3f})')
    
    ax.set_xlabel("Ce (mg/L)", fontsize=12)
    ax.set_ylabel("qe (mg/g)", fontsize=12)
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax.grid(True, alpha=0.3)
    
    # T√≠tulo din√¢mico baseado no tratamento
    if outlier_method == "Nenhum":
        title = "Isotermas ajustadas - Sem tratamento de outliers"
    else:
        title = f"Isotermas ajustadas - {outlier_method} - {outlier_action}"
    ax.set_title(title, fontsize=14)
    
    plt.tight_layout()
    st.pyplot(fig)
    
    # Download da figura
    png_buf = io.BytesIO()
    fig.savefig(png_buf, format="png", bbox_inches="tight", dpi=200)
    st.download_button("üì• Baixar figura (.png)", data=png_buf.getvalue(), 
                      file_name="isotermas_analise.png", mime="image/png")
    
    # Download do pacote completo
    excel_buf = io.BytesIO()
    with pd.ExcelWriter(excel_buf, engine="openpyxl") as writer:
        df.to_excel(writer, sheet_name="dados_originais", index=False)
        result_df.reset_index().to_excel(writer, sheet_name="parametros", index=False)
        pred_df.to_excel(writer, sheet_name="curvas_preditas", index=False)
        if outlier_method != "Nenhum" and np.any(outliers):
            outlier_df.to_excel(writer, sheet_name="outliers_detectados", index=False)
    
    st.download_button("üì¶ Baixar pacote completo (.xlsx)", data=excel_buf.getvalue(),
                      file_name="isotermas_analise_completa.xlsx",
                      mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

else:
    st.info("üìÅ Carregue um arquivo para come√ßar. Layout sugerido: **Ce, qe, sigma_Ce, sigma_qe**.")
    
    # Informa√ß√µes sobre bounds
    st.markdown("### ‚öôÔ∏è **Configura√ß√µes de Bounds Dispon√≠veis**")
    st.markdown("""
    Este aplicativo oferece tr√™s modos de bounds para par√¢metros:
    
    - **üÜì Livres (sem limita√ß√£o)**: Ideal para explorar sistemas desconhecidos ou com alta capacidade
    - **üéØ Conservadores**: Baseados nos dados experimentais - qmax limitado a 200% dos dados (ATUALIZADO)
    - **üîí Ultra-restritivos**: Para sistemas onde se conhece o limite f√≠sico (~115 mg/g)
    
    **üí° Recomenda√ß√£o**: Para sistemas como MFC/8B@CO que atingem ~55 mg/g, use bounds **Conservadores**.
    """)
    
    # Dados de exemplo
    demo = pd.DataFrame({
        "Ce": [18.10, 47.10, 73.85, 99.10, 177.85],
        "qe": [35.50, 62.15, 85.90, 112.85, 90.20],
        "sigma_Ce": [1.60, 0.90, 3.75, 5.80, 12.65],
        "sigma_qe": [2.70, 4.15, 1.30, 5.25, 11.80]
    })
    
    st.markdown("### üìä **Exemplo de dados**")
    st.dataframe(demo, use_container_width=True)
    
    st.download_button("üì• Baixar planilha modelo (.csv)", 
                      data=demo.to_csv(index=False).encode("utf-8"),
                      file_name="isotermas_modelo.csv", mime="text/csv")
